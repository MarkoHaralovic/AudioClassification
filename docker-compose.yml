version: '3.8'
services:
  flask_app:
    build: ./API
    image: api-flask_app
    ports:
      - '8080:8080'
    volumes:
      - './API:/app'
  tfserving:
    build:
      context: .
      dockerfile: ./tfserving/Dockerfile
    image: api-tfserving
    ports:
      - '8500:8500'
      - '8501:8501'
    volumes:
      - './API/model:/models'
      - './API/config/model_config_file.conf:/models.config'
    entrypoint: tensorflow_model_server --port=8500 --rest_api_port=8501 --model_config_file=/models.config --enable_model_warmup=true
    command: --port=8500 --rest_api_port=8501 --model_config_file=/models.config --enable_model_warmup=true

